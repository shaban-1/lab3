{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP0ZvWDVt0JxtdnG0uvWr2k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaban-1/lab3/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x25tIRgtuCcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb12f160-f4c6-4c6c-e0de-5ccdf76d6e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fengzhang427/HEP.git\n",
        "%cd HEP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2yqeL_zvibV",
        "outputId": "1dfc72be-c33f-49bc-9ed3-d33a7849b0a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HEP'...\n",
            "remote: Enumerating objects: 103, done.\u001b[K\n",
            "remote: Total 103 (delta 0), reused 0 (delta 0), pack-reused 103 (from 1)\u001b[K\n",
            "Receiving objects: 100% (103/103), 23.75 MiB | 36.68 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n",
            "/content/HEP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python LUM_train.py --light_config configs/unit_LUM.yaml --output_path ./light"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm6ePseTyksU",
        "outputId": "d5230ae0-53b1-48ba-8db6-aee9c375effa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start training\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[*] Number of training data: 15\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[*] Evaluating for phase train / epoch 20...\n",
            "===> Iteration[20]: psnr: 7.104648731781225, ssim:0.18823021145835891\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[*] Evaluating for phase train / epoch 40...\n",
            "===> Iteration[40]: psnr: 7.104648731781225, ssim:0.18823021145835891\n",
            "[*] Evaluating for phase train / epoch 60...\n",
            "===> Iteration[60]: psnr: 7.104648731781224, ssim:0.18823021145835891\n",
            "[*] Evaluating for phase train / epoch 80...\n",
            "===> Iteration[80]: psnr: 7.104648731781224, ssim:0.1882302114583589\n",
            "[*] Evaluating for phase train / epoch 100...\n",
            "===> Iteration[100]: psnr: 7.104648731781225, ssim:0.1882302114583589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python LUM_test.py --LUM_config configs/unit_LUM.yaml --input_folder ./test_images --output_folder ./result_images --LUM_checkpoint ./LUM_checkpoint/LUM_LOL.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVHCW0ENzCtf",
        "outputId": "a814363b-ca82-4848-fa9a-7829816d436a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179.png\n",
            "Time taken for 179.png: 0.2230 seconds\n",
            "22.png\n",
            "Time taken for 22.png: 0.0052 seconds\n",
            "55.png\n",
            "Time taken for 55.png: 0.0016 seconds\n",
            "146.png\n",
            "Time taken for 146.png: 0.0022 seconds\n",
            "778.png\n",
            "Time taken for 778.png: 0.0025 seconds\n",
            "665.png\n",
            "Time taken for 665.png: 0.0015 seconds\n",
            "23.png\n",
            "Time taken for 23.png: 0.0024 seconds\n",
            "547.png\n",
            "Time taken for 547.png: 0.0021 seconds\n",
            "748.png\n",
            "Time taken for 748.png: 0.0023 seconds\n",
            "669.png\n",
            "Time taken for 669.png: 0.0022 seconds\n",
            "780.png\n",
            "Time taken for 780.png: 0.0020 seconds\n",
            "79.png\n",
            "Time taken for 79.png: 0.0019 seconds\n",
            "111.png\n",
            "Time taken for 111.png: 0.0019 seconds\n",
            "493.png\n",
            "Time taken for 493.png: 0.0026 seconds\n",
            "1.png\n",
            "Time taken for 1.png: 0.0020 seconds\n"
          ]
        }
      ]
    }
  ]
}